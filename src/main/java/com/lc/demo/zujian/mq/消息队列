
1.为什么使用消息队列
解耦
异步
削峰

2. ActiveMQ   RabbitMQ  RocketMQ  Kafka  优缺点

--单机吞吐量  万级  万级   10万级   10万级

--topic 数量对吞吐量的影响
            RocketMQ：topic可以达到几百/几千级别，吞吐量会有较小幅度下降。这是 RocketMQ 的一大优势，在同等机器下，可以支撑大 量的 topic
            Kafka：topic 从几十到几百个的时候，吞吐量会有大幅下降。如果要支撑大规模的topic，需要增加更多的机器资源

--时效性  ms us  ms ms   RabbitMQ的一大特点，延迟最低

--可用性  基于主从架构实现高可用（）ActiveMQ和RabbitMQ；非常高，基于分布式架构（RocketMQ和Kafka）

--消息可靠性  有较低概率会丢失数据   基本不丢失  经过参数优化配置可以做到 0 丢失（RocketMQ 和 Kafka）

--功能支持   完备；  基于 erlang 开发，并发能力很强，性能极好，延时很低；  MQ功能较为完善，还是分布式的，扩展性好；功能较为简单，主要支持简单MQ功能，在大数据领域的实时计算以及日志采集被大规模使用


3.如何保证消息队列的高可用

--RabbitMQ:镜像集群
--Kafka：分布式消息，broker topic partition replica (leader+follower)

4.如何保证消息的可靠性传输
--从 生产者、MQ、消费者侧面上
--RabbitMQ: conform   持久化  关闭自动 ack
--Kafka：① 消费者取消自动提交 offset
        ②优化配置参数做到消息 0 丢失
            给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
            在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader挂了还有一个 follower 吧
            在 producer 端设置 acks=all ：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。
            在 producer 端设置 retries=MAX （很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了


5.如何保证消息不被重复消费？如何保证消息的幂等性
--重复消费的场景
--处理保证消息幂等性
    比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧
    比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
    比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可
    比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

6.如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？
--本质解决消息堆积

7.如何保证消息的顺序性？
--RabbitMQ:拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；
           或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理

--Kafka：一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个
        写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性